{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fce7ef74a972>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \"\"\"\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "hw2main.py\n",
    "\n",
    "UNSW COMP9444 Neural Networks and Deep Learning\n",
    "\n",
    "DO NOT MODIFY THIS FILE\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "import student\n",
    "\n",
    "def main():\n",
    "    # Use a GPU if available, as it should be faster.\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    student.device = device\n",
    "    print(\"Using device: {}\"\n",
    "          \"\\n\".format(str(device)))\n",
    "\n",
    "    # Load the training dataset, and create a dataloader to generate a batch.\n",
    "    textField = data.Field(lower=True, include_lengths=True, batch_first=True,\n",
    "                           preprocessing=student.preprocessing,\n",
    "                           postprocessing=student.postprocessing,\n",
    "                           stop_words=student.stopWords)\n",
    "    labelField = data.Field(sequential=False, use_vocab=False, is_target=True)\n",
    "\n",
    "    dataset = data.TabularDataset('train.json', 'json',\n",
    "                                 {'reviewText': ('reviewText', textField),\n",
    "                                  'rating': ('rating', labelField)})\n",
    "\n",
    "    textField.build_vocab(dataset, vectors=student.wordVectors)\n",
    "\n",
    "    # Allow training on the entire dataset, or split it for training and validation.\n",
    "    if student.trainValSplit == 1:\n",
    "        trainLoader = data.BucketIterator(dataset, shuffle=True,\n",
    "                                          batch_size=student.batchSize,\n",
    "                                          sort_key=lambda x: len(x.reviewText),\n",
    "                                          sort_within_batch=True)\n",
    "    else:\n",
    "        train, validate = dataset.split(split_ratio=student.trainValSplit,\n",
    "                                        stratified=True, strata_field='rating')\n",
    "\n",
    "        trainLoader, valLoader = data.BucketIterator.splits(\n",
    "            (train, validate), shuffle=True, batch_size=student.batchSize,\n",
    "             sort_key=lambda x: len(x.reviewText), sort_within_batch=True)\n",
    "\n",
    "    # Get model and optimiser from student.\n",
    "    net = student.net.to(device)\n",
    "    criterion = student.lossFunc\n",
    "    optimiser = student.optimiser\n",
    "\n",
    "    # Train.\n",
    "    for epoch in range(student.epochs):\n",
    "        runningLoss = 0\n",
    "\n",
    "        for i, batch in enumerate(trainLoader):\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs = textField.vocab.vectors[batch.reviewText[0]].to(device)\n",
    "            length = batch.reviewText[1].to(device)\n",
    "            labels = batch.rating.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # PyTorch calculates gradients by accumulating contributions\n",
    "            # to them (useful for RNNs).\n",
    "            # Hence we must manually set them to zero before calculating them.\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Forward pass through the network.\n",
    "            output = net(inputs, length)\n",
    "            loss = criterion(output, student.convertLabel(labels))\n",
    "\n",
    "            # Calculate gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Minimise the loss according to the gradient.\n",
    "            optimiser.step()\n",
    "\n",
    "            runningLoss += loss.item()\n",
    "\n",
    "            if i % 32 == 31:\n",
    "                print(\"Epoch: %2d, Batch: %4d, Loss: %.3f\"\n",
    "                      % (epoch + 1, i + 1, runningLoss / 32))\n",
    "                runningLoss = 0\n",
    "\n",
    "    # Save model.\n",
    "    torch.save(net.state_dict(), 'savedModel.pth')\n",
    "    print(\"\\n\"\n",
    "          \"Model saved to savedModel.pth\")\n",
    "\n",
    "    # Test on validation data if it exists.\n",
    "    if student.trainValSplit != 1:\n",
    "        net.eval()\n",
    "\n",
    "        closeness = [0 for _ in range(5)]\n",
    "        with torch.no_grad():\n",
    "            for batch in valLoader:\n",
    "                # Get a batch and potentially send it to GPU memory.\n",
    "                inputs = textField.vocab.vectors[batch.reviewText[0]].to(device)\n",
    "                length = batch.reviewText[1].to(device)\n",
    "                labels = batch.rating.type(torch.FloatTensor).to(device)\n",
    "\n",
    "                # Convert network output to integer values.\n",
    "                outputs = student.convertNetOutput(net(inputs, length)).flatten()\n",
    "\n",
    "                for i in range(5):\n",
    "                    closeness[i] += torch.sum(abs(labels - outputs) == i).item()\n",
    "\n",
    "        accuracy = [x / len(validate) for x in closeness]\n",
    "        score = 100 * (accuracy[0] + 0.4 * accuracy[1])\n",
    "\n",
    "        print(\"\\n\"\n",
    "              \"Correct predictions: {:.2%}\\n\"\n",
    "              \"One star away: {:.2%}\\n\"\n",
    "              \"Two stars away: {:.2%}\\n\"\n",
    "              \"Three stars away: {:.2%}\\n\"\n",
    "              \"Four stars away: {:.2%}\\n\"\n",
    "              \"\\n\"\n",
    "              \"Weighted score: {:.2f}\".format(*accuracy, score))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
